# -*- coding: utf-8 -*-
"""Diabetes Dataset EDA.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Es45KvTR7JJIehcEr_mD79cA6wWGcUnL
"""

# This Python 3 environment comes with many helpful analytics libraries installed
# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python
# For example, here's several helpful packages to load

import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)

# Input data files are available in the read-only "../input/" directory
# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory

import os
for dirname, _, filenames in os.walk('/kaggle/input'):
    for filename in filenames:
      print(os.path.join(dirname, filename))

# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using "Save & Run All"
# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session

# Importation des bibliothèques nécessaires
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt

file_path = '/content/bdd diabet.csv'  # Updated path to the dataset
df = pd.read_csv(file_path, sep=';')

print(df.head())

print(df.columns)

print(df.info())

print( df.describe())

print(df.isnull().sum())

plt.figure(figsize=(8, 6))
sns.histplot(df['Age'], bins=20, kde=True)
plt.title('Distribution de l\'Âge')
plt.xlabel('Âge')
plt.ylabel('Fréquence')
plt.show()

plt.figure(figsize=(8, 6))
sns.histplot(df['BMI'], bins=20, kde=True)
plt.title('Distribution du BMI')
plt.xlabel('BMI')
plt.ylabel('Fréquence')
plt.show()

plt.figure(figsize=(8, 6))
sns.histplot(df['Insulin Levels'], bins=20, kde=True)
plt.title('Distribution des niveaux d\'insuline')
plt.xlabel('Niveaux d\'insuline')
plt.ylabel('Fréquence')
plt.show()

plt.figure(figsize=(10, 6))
sns.countplot(x='Target', data=df)
plt.xticks(rotation=90)
plt.title('Répartition des différents types de diabète')
plt.show()

plt.figure(figsize=(8, 6))
sns.countplot(x='Family History', data=df)
plt.title('Répartition des antécédents familiaux')
plt.show()

plt.figure(figsize=(10, 6))
sns.boxplot(x='Target', y='Age', data=df)
plt.xticks(rotation=90)
plt.title('Distribution de l\'Âge par Type de Diabète')
plt.show()

plt.figure(figsize=(10, 6))
sns.countplot(x='Target', hue='Family History', data=df)
plt.xticks(rotation=90)
plt.title('Antécédents familiaux par Type de Diabète')
plt.show()

df_numeric = df.select_dtypes(include='number')


corr_matrix = df_numeric.corr()


plt.figure(figsize=(15, 10))
sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', fmt='.2f')
plt.title('Matrice de Corrélation des Variables Numériques')
plt.show()

for col in df.select_dtypes(include=['object']).columns:
    print(f"Valeurs uniques pour la colonne {col} :")
    print(df[col].value_counts())
    print("\n" + "-"*50 + "\n")

df[['BMI', 'Blood Pressure', 'Insulin Levels']].boxplot()
plt.show()

df['Genetic Markers'].value_counts().plot(kind='bar')
plt.title('Répartition des marqueurs génétiques')
plt.show()

import seaborn as sns
import matplotlib.pyplot as plt

sns.boxplot(x='Target', y='Insulin Levels', data=df)
plt.xticks(rotation=90)
plt.show()

plt.figure(figsize=(10, 6))
sns.scatterplot(x='Age', y='Blood Pressure', hue='Target', data=df, palette='Set1')

plt.title('Blood Pressure en fonction de l\'âge, par type de diabète')
plt.xlabel('Âge')
plt.ylabel('Pression Sanguine')

plt.legend(title='Type de diabète', bbox_to_anchor=(1.05, 1), loc='upper left')
plt.tight_layout()  # Pour s'assurer que tout est bien ajusté
plt.show()

plt.figure(figsize=(10, 6))
sns.scatterplot(x='Age', y='Cholesterol Levels', hue='Target', data=df, palette='Set1')

plt.title('Cholesterol Levels en fonction de l\'âge, par type de diabète')
plt.xlabel('Âge')
plt.ylabel('Niveaux de Cholestérol')

# Déplacer la légende à côté du graphique
plt.legend(title='Type de diabète', bbox_to_anchor=(1.05, 1), loc='upper left')
plt.tight_layout()  # Ajustement pour éviter les chevauchements
plt.show()

import seaborn as sns
import matplotlib.pyplot as plt

# Créer un scatter plot pour visualiser la circonférence de la taille en fonction de l'âge
plt.figure(figsize=(10, 6))
sns.scatterplot(x='Age', y='Waist Circumference', hue='Target', data=df, palette='Set1')

# Ajouter des titres et des labels
plt.title('Circonférence de la taille en fonction de l\'âge, par type de diabète')
plt.xlabel('Âge')
plt.ylabel('Circonférence de la taille')
# Déplacer la légende à côté du graphique
plt.legend(title='Type de diabète', bbox_to_anchor=(1.05, 1), loc='upper left')
plt.tight_layout()  # Pour s'assurer que tout est bien ajusté
plt.show()

import seaborn as sns
import matplotlib.pyplot as plt

# Créer un scatter plot pour visualiser la fonction pulmonaire en fonction des niveaux de glucose dans le sang
plt.figure(figsize=(10, 6))
sns.scatterplot(x='Blood Glucose Levels', y='Pulmonary Function', hue='Target', data=df, palette='Set1')

# Ajouter des titres et des labels
plt.title('Fonction pulmonaire en fonction des niveaux de glucose dans le sang, par type de diabète')
plt.xlabel('Niveaux de Glucose dans le Sang')
plt.ylabel('Fonction Pulmonaire')
# Déplacer la légende à côté du graphique
plt.legend(title='Type de diabète', bbox_to_anchor=(1.05, 1), loc='upper left')
plt.tight_layout()  # Ajuster pour éviter les chevauchements
plt.show()

import seaborn as sns
import matplotlib.pyplot as plt

# Créer un scatter plot pour visualiser la fonction pulmonaire en fonction de la santé pancréatique
plt.figure(figsize=(10, 6))
sns.scatterplot(x='Pancreatic Health', y='Pulmonary Function', hue='Target', data=df, palette='Set1')
# Ajouter des titres et des labels
plt.title('Fonction pulmonaire en fonction de la santé pancréatique, par type de diabète')
plt.xlabel('Santé Pancréatique')
plt.ylabel('Fonction Pulmonaire')

# Déplacer la légende à côté du graphique
plt.legend(title='Type de diabète', bbox_to_anchor=(1.05, 1), loc='upper left')
plt.tight_layout()  # Ajustement pour éviter les chevauchements
plt.show()

# Importation des bibliothèques nécessaires
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, classification_report, mean_squared_error
from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.svm import SVC
from sklearn.neighbors import KNeighborsClassifier
from sklearn.ensemble import GradientBoostingClassifier
from xgboost import XGBClassifier
from lightgbm import LGBMClassifier
from sklearn.ensemble import AdaBoostClassifier
from sklearn.naive_bayes import GaussianNB
from sklearn.neural_network import MLPClassifier

# Chargement des données
df = pd.read_csv('/content/bdd diabet.csv', sep=';') # Corrected file path and added separator
# Affichage des 5 premières lignes du DataFrame
df.head()

# Affichage complet des colonnes
pd.set_option('display.max_columns', None)

# Calcul des valeurs manquantes
nan_percentage = df.isna().sum() / df.count() * 100
nan_count = df.isna().sum()
nan_table = pd.concat([nan_count, nan_percentage], axis=1)
nan_table.columns = ['Count', 'Percentage']
nan_table
# Mapping pour la colonne Target (type de diabète)
target_mapping = {
  'Cystic Fibrosis-Related Diabetes (CFRD)': 0,
  'Gestational Diabetes': 1,
  'LADA': 2,
  'MODY': 3,
  'Neonatal Diabetes Mellitus (NDM)': 4,
  'Prediabetic': 5,
  'Secondary Diabetes': 6,
  'Steroid-Induced Diabetes': 7,
  'Type 1 Diabetes': 8,
  'Type 2 Diabetes': 9,
  'Type 3c Diabetes (Pancreatogenic Diabetes)': 10,
  'Wolcott-Rallison Syndrome': 11,
  'Wolfram Syndrome': 12
  }

# Mapping pour les autres colonnes catégorielles
genetic_markers_mapping = {'Negative': 0, 'Positive': 1}
autoantibodies_mapping = {'Negative': 0, 'Positive': 1}
family_history_mapping = {'No': 0, 'Yes': 1}
environmental_factors_mapping = {'Absent': 0, 'Present': 1}
physical_activity_mapping = {'Low': 0, 'Moderate': 1, 'High': 2}
dietary_habits_mapping = {'Unhealthy': 0, 'Healthy': 1}
ethnicity_mapping = {'Low Risk': 0, 'High Risk': 1}
socioeconomic_factors_mapping = {'Low': 0, 'Medium': 1, 'High': 2}
smoking_status_mapping = {'Non-Smoker': 0, 'Smoker': 1}
alcohol_consumption_mapping = {'Low': 0, 'Moderate': 1, 'High': 2}
glucose_tolerance_test_mapping = {'Normal': 0, 'Abnormal': 1}
history_of_pcos_mapping = {'No': 0, 'Yes': 1}
previous_gestational_diabetes_mapping = {'No': 0, 'Yes': 1}
pregnancy_history_mapping = {'Normal': 0, 'Complications': 1}
cystic_fibrosis_diagnosis_mapping = {'No': 0, 'Yes': 1}
steroid_use_history_mapping = {'No': 0, 'Yes': 1}
genetic_testing_mapping = {'Negative': 0, 'Positive': 1}
liver_function_tests_mapping = {'Normal': 0, 'Abnormal': 1}
urine_test_mapping = {'Normal': 0, 'Protein Present': 1, 'Ketones Present': 2, 'Glucose Present': 3}
early_onset_symptoms_mapping = {'No': 0, 'Yes': 1}
# Application du mapping sur les colonnes du DataFrame
df['Target'] = df['Target'].map(target_mapping)
df['Genetic Markers'] = df['Genetic Markers'].map(genetic_markers_mapping)
df['Autoantibodies'] = df['Autoantibodies'].map(autoantibodies_mapping)
df['Family History'] = df['Family History'].map(family_history_mapping)
df['Environmental Factors'] = df['Environmental Factors'].map(environmental_factors_mapping)
df['Physical Activity'] = df['Physical Activity'].map(physical_activity_mapping)
df['Dietary Habits'] = df['Dietary Habits'].map(dietary_habits_mapping)
df['Ethnicity'] = df['Ethnicity'].map(ethnicity_mapping)
df['Socioeconomic Factors'] = df['Socioeconomic Factors'].map(socioeconomic_factors_mapping)
df['Smoking Status'] = df['Smoking Status'].map(smoking_status_mapping)
df['Alcohol Consumption'] = df['Alcohol Consumption'].map(alcohol_consumption_mapping)
df['Glucose Tolerance Test'] = df['Glucose Tolerance Test'].map(glucose_tolerance_test_mapping)
df['History of PCOS'] = df['History of PCOS'].map(history_of_pcos_mapping)
df['Previous Gestational Diabetes'] = df['Previous Gestational Diabetes'].map(previous_gestational_diabetes_mapping)
df['Pregnancy History'] = df['Pregnancy History'].map(pregnancy_history_mapping)
df['Cystic Fibrosis Diagnosis'] = df['Cystic Fibrosis Diagnosis'].map(cystic_fibrosis_diagnosis_mapping)
df['Steroid Use History'] = df['Steroid Use History'].map(steroid_use_history_mapping)
df['Genetic Testing'] = df['Genetic Testing'].map(genetic_testing_mapping)
df['Liver Function Tests'] = df['Liver Function Tests'].map(liver_function_tests_mapping)
df['Urine Test'] = df['Urine Test'].map(urine_test_mapping)
df['Early Onset Symptoms'] = df['Early Onset Symptoms'].map(early_onset_symptoms_mapping)

# Le DataFrame `df` est maintenant prêt avec des variables catégorielles encodées en valeurs numériques

# 1. Séparation des caractéristiques (features) et de la cible (target)
X = df.drop('Target', axis=1)  # Caractéristiques (features)
y = df['Target']  # Cible (Target)

# 2. Division des données en ensembles d'entraînement et de test
from sklearn.model_selection import train_test_split

# Division en ensemble d'entraînement (80%) et de test (20%)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
# 3. Normalisation des données (si nécessaire)
from sklearn.preprocessing import StandardScaler

# Initialisation du scaler pour la normalisation
scaler = StandardScaler()

# Normalisation des données d'entraînement et de test
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# 4. Entraînement d'un modèle de machine learning (Random Forest Classifier)
from sklearn.ensemble import RandomForestClassifier
# Initialisation du modèle Random Forest
# Limitation du nombre d'arbres et de la profondeur pour éviter les problèmes de mémoire
rf_model = RandomForestClassifier(n_estimators=100, max_depth=10, random_state=42)

# Entraînement du modèle sur les données d'entraînement
rf_model.fit(X_train_scaled, y_train)

# Prédictions sur l'ensemble de test
y_pred = rf_model.predict(X_test_scaled)

# 5. Évaluation du modèle
from sklearn.metrics import accuracy_score, classification_report
# Calcul de la précision du modèle
accuracy = accuracy_score(y_test, y_pred)
print(f'Précision du modèle : {accuracy * 100:.2f}%')

# Rapport de classification détaillé
print("Rapport de classification :")
print(classification_report(y_test, y_pred))

# 6. Essayer un autre modèle : SVM
from sklearn.svm import SVC

# Initialisation et entraînement d'un modèle SVM
svm_model = SVC()
svm_model.fit(X_train_scaled, y_train)
# Prédictions avec le modèle SVM
y_pred_svm = svm_model.predict(X_test_scaled)

# Évaluer la précision du modèle SVM
accuracy_svm = accuracy_score(y_test, y_pred_svm)
print(f'Précision du modèle SVM : {accuracy_svm * 100:.2f}%')

# 7. Validation croisée pour le modèle Random Forest
from sklearn.model_selection import cross_val_score
# Validation croisée avec Random Forest
# Limitation du nombre de jobs parallèles pour éviter de surcharger la mémoire
cv_scores = cross_val_score(rf_model, X_train_scaled, y_train, cv=5, n_jobs=2)
print(f'Précision moyenne avec validation croisée (Random Forest) : {cv_scores.mean() * 100:.2f}%')

# 8. Optimisation des hyperparamètres (facultatif, GridSearchCV par exemple)
from sklearn.model_selection import GridSearchCV

# Définir les hyperparamètres à tester pour Random Forest
# Limitation des paramètres pour éviter les problèmes de performance
param_grid = {
    'n_estimators': [50, 100],  # Limitation du nombre d'arbres pour réduire la charge mémoire
    'max_depth': [10, 20],      # Limitation de la profondeur des arbres
    'min_samples_split': [2, 5]
}

# Optimisation des hyperparamètres avec GridSearchCV
# Limitation du nombre de jobs parallèles pour éviter les surcharges
grid_search = GridSearchCV(estimator=rf_model, param_grid=param_grid, cv=5, n_jobs=2, verbose=2)
grid_search.fit(X_train_scaled, y_train)

# Meilleurs paramètres trouvés
print(f'Meilleurs hyperparamètres : {grid_search.best_params_}')
# Réentraîner le modèle avec les meilleurs paramètres
best_rf_model = grid_search.best_estimator_
y_pred_best_rf = best_rf_model.predict(X_test_scaled)

# Évaluation du modèle optimisé
accuracy_best_rf = accuracy_score(y_test, y_pred_best_rf)
print(f'Précision du modèle Random Forest optimisé : {accuracy_best_rf * 100:.2f}%')